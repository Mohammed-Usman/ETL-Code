{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "adequate-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "posted-exploration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# spark = (\n",
    "#     SparkSession.builder\n",
    "#     .appName(\"SparkETLExample\")\n",
    "#     .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "metallic-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"first_name\tlast_name\tsalary\tdept_name\tsalary_increment\".replace(\"\t\",\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "joint-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_schema = \"first_name STRING, last_name STRING, salary INT, \\ndept_name STRING, salary_increment float\"\n",
    "# flat_data = \"flat_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "featured-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_file = spark.read.format(\"csv\").schema(flat_schema).option(\"header\",\"true\").load(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "abandoned-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #kya e lazmi ha k new file me dpartmane unique hongy?\n",
    "# #kya e lazmi ha k new file me name unique hongy?\n",
    "# unique_dept = flat_file.select(\"dept_name\",\"salary_increment\").distinct()\n",
    "# unique_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "thirty-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_dept.createOrReplaceTempView(\"newDeptData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "friendly-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"SELECT * FROM newDeptData\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "considered-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession \\\n",
    "#         .builder \\\n",
    "#         .appName(\"Python Spark SQL data source example\") \\\n",
    "#         .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "unavailable-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = (\n",
    "#     spark\n",
    "#     .read \n",
    "    \n",
    "#     .jdbc(\"jdbc:postgresql://localhost:5432/etlcode\", \"com_dim_city\",properties={\"user\": \"postgres\", \"password\": \"usman123\"})\n",
    "# )\n",
    "\n",
    "# df.createOrReplaceTempView(\"[your_table]\")\n",
    "\n",
    "# sqlDF = spark.sql(\"SELECT * FROM [your_table] LIMIT 10\")\n",
    "# sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "elementary-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# the Spark session should be instantiated as follows\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.jars\", \"/home/usman/Downloads/postgresql-42.2.19.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "handed-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_schema = \"first_name STRING, last_name STRING, salary INT, \\ndept_name STRING, salary_increment float\"\n",
    "flat_data = \"flat_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fallen-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_file = spark.read.format(\"csv\").schema(flat_schema).option(\"header\",\"true\").load(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "another-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|dept_name|salary_increment|\n",
      "+---------+----------------+\n",
      "|Marketing|            16.0|\n",
      "|    Sales|            17.0|\n",
      "|       IT|            15.0|\n",
      "|  Finance|            10.0|\n",
      "+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kya e lazmi ha k new file me dpartmane unique hongy?\n",
    "#kya e lazmi ha k new file me name unique hongy?\n",
    "unique_dept = flat_file.select(\"dept_name\",\"salary_increment\").distinct()\n",
    "unique_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "certain-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='jdbc:postgresql://localhost:5432/etlcode' # jdbc:postgresql://<host>:<port>/<database>\n",
    "dbtable='department'\n",
    "user='postgres'\n",
    "password=\"usman123\"\n",
    "driver='org.postgresql.Driver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "hydraulic-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF = spark.read.format(\"jdbc\"). \\\n",
    "options(\n",
    "         url= url,\n",
    "         dbtable='department',\n",
    "         user=user,\n",
    "         password=password,\n",
    "         driver=driver\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "german-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                  id|     name|    salary_increment|\n",
      "+--------------------+---------+--------------------+\n",
      "|ec09fd05-b2d4-4b1...|    Sales|10.00000000000000...|\n",
      "|f1cdd777-357b-47d...|Marketing|16.00000000000000...|\n",
      "|4e46d780-cf04-486...|  Finance|10.00000000000000...|\n",
      "|ba570a7f-f189-46c...|       IT|15.00000000000000...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "emerging-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = (\n",
    "#     spark.\n",
    "#     read.\n",
    "#     jdbc(url = \"jdbc:postgresql://localhost:5432/database_example\",\\\n",
    "#          table = \"(SELECT Employee.id, Employee.name AS employee_name, Employee.salary, Employee.departmentid, Department.name AS department_name \\\n",
    "#                      FROM Employee INNER JOIN Department ON Employee.DepartmentId = Department.ID) AS my_table\",\n",
    "#                      properties={\"user\": \"postgres\", \"password\": \"1234\", \"driver\": 'org.postgresql.Driver'}).createTempView('tbl')\n",
    "#      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "strange-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#depart = (jdbcDF.join(unique_dept,jdbcDF.name != unique_dept.dept_name, how=\"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fabulous-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "#depart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "protecting-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dept.createOrReplaceTempView(\"newDeptData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "center-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF.createOrReplaceTempView(\"oldDeptData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "decreased-cambodia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|dept_name|salary_increment|\n",
      "+---------+----------------+\n",
      "|Marketing|            16.0|\n",
      "|    Sales|            17.0|\n",
      "|       IT|            15.0|\n",
      "|  Finance|            10.0|\n",
      "+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM newDeptData\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "hungarian-tumor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                  id|     name|    salary_increment|\n",
      "+--------------------+---------+--------------------+\n",
      "|ec09fd05-b2d4-4b1...|    Sales|10.00000000000000...|\n",
      "|f1cdd777-357b-47d...|Marketing|16.00000000000000...|\n",
      "|4e46d780-cf04-486...|  Finance|10.00000000000000...|\n",
      "|ba570a7f-f189-46c...|       IT|15.00000000000000...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM oldDeptData\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "expected-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.readwriter.DataFrameReader at 0x7f3f2c461190>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"jdbc\"). \\\n",
    "options(\n",
    "         url= url,\n",
    "        query = \"UPDATE department SET name = 'S' WHERE name = 'Sales' \",\n",
    "         user=user,\n",
    "         password=password,\n",
    "         driver=driver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "realistic-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                  id|     name|    salary_increment|\n",
      "+--------------------+---------+--------------------+\n",
      "|ec09fd05-b2d4-4b1...|    Sales|10.00000000000000...|\n",
      "|f1cdd777-357b-47d...|Marketing|16.00000000000000...|\n",
      "|4e46d780-cf04-486...|  Finance|10.00000000000000...|\n",
      "|ba570a7f-f189-46c...|       IT|15.00000000000000...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "polish-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|    salary_increment|salary_increment|\n",
      "+--------------------+----------------+\n",
      "|10.00000000000000...|            17.0|\n",
      "|16.00000000000000...|            16.0|\n",
      "|10.00000000000000...|            10.0|\n",
      "|15.00000000000000...|            15.0|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1st \n",
    "#update existing depart's salary_increment\n",
    "spark.sql(\"\"\"\n",
    "SELECT odd.salary_increment,ndd.salary_increment FROM newDeptData as ndd\n",
    "INNER JOIN oldDeptData odd on ndd.dept_name = odd.name\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "efficient-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "# insert new depart\n",
    "dept_col = spark.sql(\"\"\"\n",
    "SELECT ndp.dept_name as name, ndp.salary_increment FROM newDeptData as ndp\n",
    "LEFT JOIN oldDeptData odd on ndp.dept_name = odd.name\n",
    "where odd.name IS NULL\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "union-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|name|salary_increment|\n",
      "+----+----------------+\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "hourly-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='jdbc:postgresql://localhost:5432/etlcode' # jdbc:postgresql://<host>:<port>/<database>\n",
    "dbtable='department'\n",
    "user='postgres'\n",
    "password=\"usman123\"\n",
    "driver='org.postgresql.Driver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "center-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop={\"user\":user,\n",
    "        \"password\":password,\n",
    "     \"driver\":\"org.postgresql.Driver\"\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "electric-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dept_col.write.jdbc(url='jdbc:postgresql://localhost:5432/etlcode', mode=\"append\",table='department', properties=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "separated-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_col.write.jdbc(url=\"jdbc:postgresql://localhost:5432/etlcode\", table=dbtable, mode=\"append\", properties=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "simple-struggle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|name|salary_increment|\n",
      "+----+----------------+\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "searching-suite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                  id|     name|    salary_increment|\n",
      "+--------------------+---------+--------------------+\n",
      "|ec09fd05-b2d4-4b1...|    Sales|10.00000000000000...|\n",
      "|f1cdd777-357b-47d...|Marketing|16.00000000000000...|\n",
      "|4e46d780-cf04-486...|  Finance|10.00000000000000...|\n",
      "|ba570a7f-f189-46c...|       IT|15.00000000000000...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ethical-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_emp_data = spark.read.format(\"jdbc\"). \\\n",
    "options(\n",
    "         url= url,\n",
    "         dbtable=\"employee\",\n",
    "         user=user,\n",
    "         password=password,\n",
    "         driver=driver\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "humanitarian-maldives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+\n",
      "| id|first_name|last_name|salary|department_id|\n",
      "+---+----------+---------+------+-------------+\n",
      "+---+----------+---------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_emp_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "coordinated-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emp_data = flat_file.select('first_name','last_name','salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "annual-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_emp_data.createOrReplaceTempView('old_emp_data')\n",
    "new_emp_data.createOrReplaceTempView('new_emp_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "toxic-skill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|old|new|\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT oed.salary as old,ned.salary as new from old_emp_data oed\n",
    "INNER JOIN new_emp_data ned on oed.first_name = ned.first_name\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "massive-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload\n",
    "# Fetch Unique Dept\n",
    "# Join get new\n",
    "# Insert new\n",
    "# Get All Dept UUId\n",
    "# Map All UUID to df\n",
    "# Department updated\n",
    "# Department Inserted\n",
    "# Department Fetched with uuid\n",
    "# Employee MApped wiht department UUID\n",
    "# Employee Updated\n",
    "# Employeee INserted\n",
    "# Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-document",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
